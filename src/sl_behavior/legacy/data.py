"""This module provides classes for representing, processing, and analyzing virtual reality data collected by the
Gimbl Virtual Reality controller library. The tools provided by this module are used to parse all legacy Tyche data and
convert it into the format generated by the modern Sun lab data processing pipelines.
"""

from typing import Any
from dataclasses import field, dataclass

import numpy as np
import polars as pl
from numpy.typing import NDArray
from scipy.interpolate import Rbf, splev, splprep
from scipy.spatial.distance import cdist
from ataraxis_base_utilities import console

from .extract import movement_speed
from .transform import add_ranged_timestamp_values


@dataclass
class IdleData:
    """Stores data specific to the 'Idle' VR task state.

    The 'Idle' state is defined as the state where the animal does not move or interact with the task environment for
    a prolonged period of time.

    Attributes:
        sound: Stores data about auditory cues emitted during the idle states.
    """

    sound: str | None = None


@dataclass
class TimeData:
    """Stores managed session's time data, which includes timestamps for each Unity frame.

    Attributes:
        time: A NumPy array of session timestamps.
        frame: A Polars DataFrame describing the state of the Virtual Reality task at each timestamp.
    """

    time: NDArray[Any] | None = None
    frame: pl.DataFrame | None = None


@dataclass
class ControllerData:
    """Stores managed session's Gimbl Virtual Reality controller data.

    Primarily, this includes the settings of the Gimbl task controller at each Unity frame.

    Attributes:
        settings: A dictionary that stores the VR controller settings or configuration parameters.
        time: A NumPy array that stores the timestamps for controller parameter updates.
        frame: A Polars DataFrame that captures the controller state at each Unity frame.
    """

    settings: dict[str, Any] | None = None
    time: NDArray[Any] | None = None
    frame: pl.DataFrame | None = None


@dataclass
class GimblData:
    """Stores all data extracted from the .json log file generated by the Gimbl Virtual Reality controller library.

    This class encapsulates multiple other nested classes for specialized data types (e.g., time-related or
    controller-related data). It also provides methods for converting between path coordinates and XYZ coordinates.

    Notes:
        This is a hybrid implementation adapted from the original VR2P parsing codebase referenced in the OSM
        manuscript: https://www.nature.com/articles/s41586-024-08548-w.

    Attributes:
        time: A NumPy array that stores the global (UTC) session timestamps.
        info: A dictionary that stores the session's general information and metadata.
        frames A Polars DataFrame that stores Unity frame data (e.g., frame indices, timestamps).
        position: A TimeData instance that stores position data, such as animal's VR coordinates at each Unity frame.
        path: A TimeData instance that stores VR path-related data, such as path names or positions along the path.
        camera: A dictionary that stores the face-camera data (e.g., camera parameters or transforms).
        reward: A dictionary that stores the water reward data (e.g., reward timings or amounts).
        lick: A dictionary that stores the lick-related data (e.g., lick detection or timing).
        idle: An IdleData instance that stores the data specific to Idle task states.
        linear_controller: A ControllerData instance used to store linear VR controller data. This is mutually exclusive
            with the spherical_controller attribute.
        spherical_controller: A ControllerData instance used to store spherical VR controller data. This is mutually
            exclusive with the linear_controller attribute.
    """

    time: NDArray[Any] | None = None
    info: dict[str, Any] | None = None
    frames: pl.DataFrame | None = None
    position: TimeData = field(default_factory=TimeData)
    path: TimeData = field(default_factory=TimeData)
    camera: dict[str, Any] | None = None
    reward: dict[str, Any] | None = None
    lick: dict[str, Any] | None = None
    idle: IdleData = field(default_factory=IdleData)
    linear_controller: ControllerData = field(default_factory=ControllerData)
    spherical_controller: ControllerData = field(default_factory=ControllerData)

    def path_to_xyz(self, values: NDArray[Any], path: str) -> NDArray[Any]:
        """Interpolates XYZ coordinates from input path positions using a B-spline fit.

        Args:
            values: The one-dimensional NumPy array of path positions.
            path: The name of the path to interpolate (must exist in self.path.frame).

        Returns:
            A multidimensional NumPy array that stores interpolated XYZ position values with shape (num_positions x 3).

        Raises:
            NameError: If the specified path is not found in self.path.frame.
        """

        # Filters the data for the requested path
        path_mask = self.path.frame["path"] == path
        if path_mask.sum() == 0:
            message = f"Could not find path with name {path} inside the .path.frame attribute"
            console.error(message=message, error=NameError)

        # Gets positions for the path
        pos_df = self.position.frame.filter(path_mask).select(["x", "y", "z"])
        path_positions = self.path.frame.filter(path_mask).select(["position"])

        # Combines the dataframes
        df = pl.concat([pos_df, path_positions.rename({"position": "path"})], how="horizontal")

        # Sorts by path and removes duplicates based on rounded path values
        df = (
            df.sort("path")
            .with_columns(pl.col("path").round(0).alias("path_r"))
            .unique(subset="path_r", keep="first")
            .drop("path_r")
        )

        # Extracts arrays for spline fitting
        x_vals = df["x"].to_numpy()
        y_vals = df["y"].to_numpy()
        z_vals = df["z"].to_numpy()
        path_vals = df["path"].to_numpy()

        # Interpolates XYZ coordinates for each path position using B-spline interpolation
        # noinspection PyTupleAssignmentBalance
        tck, _ = splprep(x=[x_vals, y_vals, z_vals], u=path_vals, s=0.01)
        xi, yi, zi = splev(values, tck)

        # Generates and returns the multidimensional NumPy array that stores interpolated XYZ coordinate values
        result = np.column_stack((xi, yi, zi))
        if result.shape[0] == 1:
            return result.flatten()
        return result

    def xyz_to_path(self, values: NDArray[Any]) -> pl.DataFrame:
        """Interpolate path positions from the input XYZ coordinates using a radial basis function (RBF).

        For each input 3D coordinate, this method determines the closest path among all available paths, then evaluates
        a radial basis function (RBF) fit to compute the corresponding path position.

        Args:
            values: A NumPy array that stores XYZ coordinates with shape (num_positions x 3).

        Returns:
            A DataFrame containing the inferred path positions. It has two columns: "position" (the path position) and
                "path" (the path name).
        """
        fits = []
        path_names = self.path.frame["path"].unique().to_numpy()

        for path_name in path_names:
            # Filters for the current path
            path_mask = self.path.frame["path"] == path_name

            # Gets positions for this path
            pos_df = self.position.frame.filter(path_mask).select(["x", "y", "z"])
            path_positions = self.path.frame.filter(path_mask).select(["position"])

            # Combines and prepares the data
            df = pl.concat([pos_df, path_positions.rename({"position": "path"})], how="horizontal")
            df = (
                df.sort("path")
                .with_columns(pl.col("path").round(0).alias("path_r"))
                .unique(subset="path_r", keep="first")
            )

            # Creates the RBF interpolator
            x_vals = df["x"].to_numpy()
            y_vals = df["y"].to_numpy()
            z_vals = df["z"].to_numpy()
            path_vals = df["path"].to_numpy()

            fits.append(Rbf(x_vals, y_vals, z_vals, path_vals, smooth=0.01))

        # Determines the closest path for the processed collection of XYZ values
        obs = self.position.frame.select(["x", "y", "z"]).to_numpy()
        dist = cdist(values, obs)

        # Interpolates path names and positions for each set of XYZ coordinates (for each position)
        result_data = []
        for i, value in enumerate(values):
            closest_idx = np.argmin(dist[i, :])
            # noinspection PyTypeChecker
            path_val = self.path.frame.row(closest_idx, named=True)["path"]
            path_ind = np.argwhere(path_names == path_val)[0][0]

            # noinspection PyTypeChecker
            pos = fits[path_ind](value[0], value[1], value[2])
            result_data.append({"position": pos, "path": path_names[path_ind]})

        # Converts the result to a Polars dataframe and returns it to caller.
        return pl.DataFrame(result_data)


@pl.api.register_dataframe_namespace("vr2p")
class Vr2pNamespace:
    """A polars DataFrame namespace that provides VR2P-specific methods for analyzing and transforming virtual reality
    data.

    This namespace allows rolling speed calculations and timed value assignments in a polars DataFrame, ensuring the
    necessary columns and formats are present. It is used when converting Gimbl .json logs to .feather files used in
    the modern Sun lab pipeline.

    Args:
        df: The DataFrame to access.

    Attributes:
        _df: Stores the Polars DataFrame wrapped by the class.

    Raises:
        AttributeError: If required columns are missing from the input DataFrame.
    """

    def __init__(self, df: pl.DataFrame) -> None:
        self._df = df

        if "time" not in self._df.columns:
            message = "Expected the input dataframe to contain the 'time' column, but the column is missing."
            console.error(message=message, error=AttributeError)

    def rolling_speed(self, window_size: int, ignore_threshold: int = 50) -> np.ndarray:
        """Calculates animal's movement speed during the session using a specific rolling time window.

        Args:
            window_size: The size of the rolling window, in milliseconds.
            ignore_threshold: The speed threshold above which measurements are considered invalid
                (teleport artifacts).

        Returns:
            The one-dimensional NumPy array that stores the calculated rolling movement speed values.
        """
        return movement_speed(self._df, window_size=window_size, ignore_threshold=ignore_threshold)

    def ranged_values(self, df: pl.DataFrame, fields: list[str]) -> pl.DataFrame:
        """Adds columns from the input DataFrame to the wrapped DataFrame, based on their timestamps.

        This method is used to iteratively merge information stored in various DataFrames into the DataFrame wrapped
        by this class instance. Uses the input 'df' DataFrame to look up the time range specified by the
        instance-wrapped '_df' DataFrame (columns "time_start" and "time_end"), then merges requested columns into the
        wrapped DataFrame.

        Args:
            df: A DataFrame with time ranges ("time_start" and "time_end") and the fields to add to the wrapped
                dataframe.
            fields: A list of column names from `df` to merge into the namespace's DataFrame.

        Returns:
            A Polars DataFrame with the requested columns added and populated by matching timestamp ranges.
        """
        return add_ranged_timestamp_values(self._df, df, fields)


@dataclass
class FieldTypes:
    """Registry of field data types used in GIMBL data processing.

    This class provides a centralized mapping of field names to their corresponding polars data types to ensure
    consistent data type conversion when loading or processing data.

    Attributes:
        fields: A Dictionary mapping field names to polars dtypes.
    """

    fields: dict[str, pl.DataType] = field(
        default_factory=lambda: {
            # Metadata fields
            "data.name": pl.Categorical,
            "data.isActive": pl.Boolean,
            "data.time": pl.Categorical,
            "data.project": pl.Categorical,
            "data.scene": pl.Categorical,
            "data.source": pl.Categorical,
            "data.loopPath": pl.Boolean,
            "data.environment": pl.Categorical,
            # Message fields
            "msg": pl.Categorical,
            "data.msg": pl.Categorical,
            "data.msg.event": pl.Categorical,
            "data.msg.id": pl.Categorical,
            "data.msg.action": pl.Categorical,
            "data.msg.type": pl.Categorical,
            "data.msg.withSound": pl.Boolean,
            "data.msg.frequency": pl.Categorical,
            # Path and navigation fields
            "data.pathName": pl.Categorical,
            "data.duration": pl.Categorical,
            "data.distance": pl.Int64,
            # Session state fields
            "data.level": pl.Int64,
            "data.epoch": pl.Int64,
            "data.lap": pl.Int64,
            "data.success": pl.Boolean,
            # Control fields
            "data.gain.forward": pl.Categorical,
            "data.gain.backward": pl.Categorical,
            "data.inputSmooth": pl.Categorical,
        }
    )
