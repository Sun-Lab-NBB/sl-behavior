from typing import Any, TypedDict
from pathlib import Path
from collections.abc import Callable as Callable

from numba import (
    njit as njit,
    prange as prange,
)
import numpy as np
from _typeshed import Incomplete
from numpy.typing import NDArray as NDArray
from sl_shared_assets import MesoscopeHardwareState
from ataraxis_communication_interface import ExtractedModuleData

_supported_systems: Incomplete
_supported_sessions: Incomplete

class _ParseTask(TypedDict):
    """An internal typing class used to enforce static typing while supporting processing microcontroller data in
    parallel."""

    func: Callable[..., None]
    output: Path
    kwargs: dict[str, Any]

def _process_module_message_batch(
    log_path: Path, file_names: list[str], onset_us: np.uint64, module_type_id: tuple[tuple[int, int], ...]
) -> dict[tuple[int, int], list[dict[str, Any]]]:
    """Processes the target batch of MicroControllerInterface-generated messages stored in the .npz log file.

    This worker function is used by the extract_logged_hardware_module_data() function to process multiple message
    batches in parallel to speed up the overall hardware module data extraction.

    Args:
        log_path: The path to the processed log file.
        file_names: The names of the individual message .npy files stored in the target archive.
        onset_us: The onset of the data acquisition, in microseconds elapsed since UTC epoch onset.
        module_type_id: The module type and ID codes to extract.

    Returns:
        A dictionary mapping module (type, id) tuples to lists of extracted data dictionaries. Each data dictionary
        contains 'event', 'timestamp', 'data', and 'command' keys.
    """

def _extract_logged_hardware_module_data(
    log_path: Path, module_type_id: tuple[tuple[int, int], ...], n_workers: int = -1
) -> tuple[ExtractedModuleData, ...]:
    """Extracts the data for the requested hardware module instances running on an Ataraxis Micro Controller (AMC)
    device from the .npz log file generated by a DataLogger instance during runtime.

    This worker function was copied from the ataraxis-communication-interface library and optimized to use
    multiprocessing to achieve a measurable speedup while processing large log files.

    Notes:
        If the target .npz archive contains fewer than 2000 messages, the processing is carried out sequentially
        regardless of the specified worker-count.

    Args:
        log_path: The path to the .npz archive file that stores the logged data generated by the
            MicroControllerInterface instance during runtime.
        module_type_id: A tuple of tuples, where each inner tuple stores the type and ID codes of a specific hardware
            module, whose data should be extracted from the archive, e.g.: ((3, 1)).
        n_workers: The number of parallel worker processes (CPU cores) to use for processing. Setting this to a value
            below 1 uses all available CPU cores. Setting this to a value of 1 conducts the processing sequentially.

    Returns:
        A tuple of ExtractedModuleData instances. Each instance stores all data extracted from the log archive for one
        specific hardware module instance.

    Raises:
        ValueError: If the input path is not valid or does not point to an existing .npz archive. If the function is
            unable to properly extract a logged data object for the target hardware module.
    """

def _interpolate_data(
    timestamps: NDArray[np.uint64], data: NDArray[Any], seed_timestamps: NDArray[np.uint64], is_discrete: bool
) -> NDArray[Any]:
    """Interpolates data values for the provided seed timestamps.

    Primarily, this service function is used to time-align different datastreams from the same source.

    Notes:
        This function expects seed_timestamps and timestamps arrays to be monotonically increasing.

        Discrete interpolated data is returned as an array with the same datatype as the input data. Continuous
        interpolated data is always returned as float_64 datatype.

        This function is specifically designed to work with Sun lab time data, which uses the unsigned integer format.

    Args:
        timestamps: The one-dimensional numpy array that stores the timestamps for the source data.
        data: The one-dimensional numpy array that stores the source datapoints.
        seed_timestamps: The one-dimensional numpy array that stores the timestamps for which to interpolate the data
            values.
        is_discrete: A boolean flag that determines whether the data is discrete or continuous.

    Returns:
        A numpy array with the same dimension as the seed_timestamps array that stores the interpolated data values.
    """

def _parse_encoder_data(
    extracted_module_data: ExtractedModuleData, output_file: Path, cm_per_pulse: np.float64
) -> None:
    """Extracts and saves the data acquired by the EncoderModule during runtime as a .feather file.

    Args:
        extracted_module_data: The ExtractedModuleData instance that stores the data logged by the module during
            runtime.
        output_file: The path to the output .feather file where to save the extracted data.
        cm_per_pulse: The conversion factor to translate raw encoder pulses into distance in centimeters.
    """

def _parse_ttl_data(extracted_module_data: ExtractedModuleData, output_file: Path) -> None:
    """Extracts and saves the data acquired by the TTLModule during runtime as a .feather file.

    Args:
        extracted_module_data: The ExtractedModuleData instance that stores the data logged by the module during
            runtime.
        output_file: The path to the output .feather file where to save the extracted data.
    """

def _parse_break_data(
    extracted_module_data: ExtractedModuleData,
    output_file: Path,
    maximum_break_strength: np.float64,
    minimum_break_strength: np.float64,
) -> None:
    """Extracts and saves the data acquired by the BreakModule during runtime as a .feather file.

    Args:
        extracted_module_data: The ExtractedModuleData instance that stores the data logged by the module during
            runtime.
        output_file: The path to the output .feather file where to save the extracted data.
        maximum_break_strength: The maximum torque of the break in Newton centimeters.
        minimum_break_strength: The minimum torque of the break in Newton centimeters.

    Notes:
        This method assumes that the break was used in the absolute force mode. Currently, it does not support
        extracting variable break power data.
    """

def _parse_valve_data(
    extracted_module_data: ExtractedModuleData,
    output_file: Path,
    scale_coefficient: np.float64,
    nonlinearity_exponent: np.float64,
) -> None:
    """Extracts and saves the data acquired by the ValveModule during runtime as a .feather file.

    Notes:
        Unlike other processing methods, this method generates a .feather dataset with 3 columns: time, dispensed
        water volume, and the state of the tone buzzer.

    Args:
        extracted_module_data: The ExtractedModuleData instance that stores the data logged by the module during
            runtime.
        output_file: The path to the output .feather file where to save the extracted data.
        scale_coefficient: Stores the scale coefficient used in the fitted power law equation that translates valve
            pulses into dispensed water volumes.
        nonlinearity_exponent: Stores the nonlinearity exponent used in the fitted power law equation that
            translates valve pulses into dispensed water volumes.
    """

def _parse_lick_data(extracted_module_data: ExtractedModuleData, output_file: Path, lick_threshold: np.uint16) -> None:
    """Extracts and saves the data acquired by the LickModule during runtime as a .feather file.

    Args:
        extracted_module_data: The ExtractedModuleData instance that stores the data logged by the module during
            runtime.
        output_file: The path to the output .feather file where to save the extracted data.
        lick_threshold: The voltage threshold for detecting the interaction with the sensor as a lick.

    Notes:
        The extraction classifies lick events based on the lick threshold used during runtime. The
        time-difference between consecutive ON and OFF event edges corresponds to the time, in microseconds, the
        tongue maintained contact with the lick tube. This may include both the time the tongue physically
        touched the tube and the time there was a conductive fluid bridge between the tongue and the lick tube.

        In addition to classifying the licks and providing binary lick state data, the extraction preserves the raw
        12-bit ADC voltages associated with each lick. This way, it is possible to spot issues with the lick detection
        system by applying a different lick threshold from the one used at runtime, potentially augmenting data
        analysis.
    """

def _parse_torque_data(
    extracted_module_data: ExtractedModuleData, output_file: Path, torque_per_adc_unit: np.float64
) -> None:
    """Extracts and saves the data acquired by the TorqueModule during runtime as a .feather file.

    Args:
        extracted_module_data: The ExtractedModuleData instance that stores the data logged by the module during
            runtime.
        output_file: The path to the output .feather file where to save the extracted data.
        torque_per_adc_unit: The conversion actor used to translate ADC units recorded by the torque sensor into
            the torque in Newton centimeter, applied by the animal to the wheel.

    Notes:
        Despite this method trying to translate the detected torque into Newton centimeters, it may not be accurate.
        Partially, the accuracy of the translation depends on the calibration of the interface class, which is very
        hard with our current setup. The accuracy also depends on the used hardware, and currently our hardware is
        not very well suited for working with millivolt differential voltage levels used by the sensor to report
        torque. Therefore, currently, it is best to treat the torque data extracted from this module as a very rough
        estimate of how active the animal is at a given point in time.
    """

def _parse_screen_data(extracted_module_data: ExtractedModuleData, output_file: Path, initially_on: bool) -> None:
    """Extracts and saves the data acquired by the ScreenModule during runtime as a .feather file.

    Args:
        extracted_module_data: The ExtractedModuleData instance that stores the data logged by the module during
            runtime.
        output_file: The path to the output .feather file where to save the extracted data.
        initially_on: Communicates the initial state of the screen at module interface initialization. This is used
            to determine the state of the screens after each processed screen toggle signal.

    Notes:
        This extraction method works similar to the TTLModule method. This is intentional, as ScreenInterface is
        essentially a group of 3 TTLModules.
    """

def _parse_module_data(
    parse_func: Callable[..., None], extracted_data: ExtractedModuleData | None, output_file: Path, **kwargs: Any
) -> Exception | None:
    """Runs a hardware module data parsing function with error handling.

    This helper function is used to parse hardware module data in parallel.

    Args:
        parse_func: The parsing function to execute.
        extracted_data: The extracted module data to parse.
        output_file: The output file path.
        **kwargs: Additional arguments for the parsing function.

    Returns:
        None if successful, Exception if an error occurs during runtime.
    """

def _extract_mesoscope_vr_actor_data(
    log_path: Path, output_directory: Path, hardware_state: MesoscopeHardwareState, workers: int
) -> None:
    """Extracts the data logged by the Actor microcontroller hardware modules used during Mesoscope-VR acquisition
    system runtime and saves it as multiple .feather files.

    Args:
        log_path: The path to the .npz archive containing the Actor microcontroller data to parse.
        output_directory: The path to the directory where to save the extracted data as uncompressed .feather files.
        hardware_state: The HardwareState instance that stores the hardware configuration of the Mesoscope-VR
            acquisition system.
        workers: The number of parallel worker processes (CPU cores) to use for processing. Setting this to a value
            less than 1 uses all available CPU cores. Setting this to 1 conducts the processing sequentially.
    """

def _extract_mesoscope_vr_sensor_data(
    log_path: Path, output_directory: Path, hardware_state: MesoscopeHardwareState, workers: int
) -> None:
    """Extracts the data logged by the Sensor microcontroller modules used during Mesoscope-VR acquisition system
    runtime and saves it as multiple .feather files.

    Args:
        log_path: The path to the .npz archive containing the Sensor microcontroller data to parse.
        output_directory: The path to the directory where to save the extracted data as uncompressed .feather files.
        hardware_state: The HardwareState instance that stores the hardware configuration of the Mesoscope-VR
            acquisition system.
        workers: The number of parallel worker processes (CPU cores) to use for processing. Setting this to a value
            less than 1 uses all available CPU cores. Setting this to 1 conducts the processing sequentially.
    """

def _extract_mesoscope_vr_encoder_data(
    log_path: Path, output_directory: Path, hardware_state: MesoscopeHardwareState, workers: int
) -> None:
    """Extracts the data logged by the Encoder microcontroller modules used during Mesoscope-VR acquisition system
    runtime and saves it as multiple .feather files.

    Args:
        log_path: The path to the .npz archive containing the Encoder microcontroller data to parse.
        output_directory: The path to the directory where to save the extracted data as uncompressed .feather files.
        hardware_state: The HardwareState instance that stores the hardware configuration of the Mesoscope-VR
            acquisition system.
        workers: The number of parallel worker processes (CPU cores) to use for processing. Setting this to a value
            less than 1 uses all available CPU cores. Setting this to 1 conducts the processing sequentially.
    """

def process_microcontroller_data(
    session_path: Path,
    log_id: int,
    manager_id: int,
    job_count: int,
    reset_tracker: bool = False,
    processed_data_root: Path | None = None,
    workers: int = -1,
) -> None:
    """Reads the specified microcontroller log .npz file and extracts the behavior data recorded by the hardware modules
    managed by the microcontroller as uncompressed .feather files.

    This function is used to process the log archives generated by any microcontroller used in the Sun lab. It assumes
    that the data was logged using the assets from the ataraxis-communication-interface library.

    Args:
        session_path: The path to the session directory for which to process the microcontroller log file.
        log_id: The name (ID) of the log archive to process, e.g. '101'.
        manager_id: The unique identifier of the manager process that manages the log processing runtime.
        job_count: The total number of jobs executed as part of the behavior processing pipeline that calls this
            function.
        reset_tracker: Determines whether to reset the tracker file before executing the runtime. This allows
            recovering from deadlocked runtimes, but otherwise should not be used to ensure runtime safety.
        processed_data_root: The absolute path to the directory where processed data from all projects is stored, if
            different from the root directory provided as part of the 'session_path' argument.
        workers: The number of worker processes to use for extracting the hardware module messages in parallel. Setting
            this argument to a value less than 1 uses all available CPU cores. Setting this to a value of 1 conducts
            the processing sequentially.
    """
