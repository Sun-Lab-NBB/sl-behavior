# Claude Code Instructions

## Session Start Behavior

At the beginning of each coding session, before making any code changes, you should build a comprehensive
understanding of the codebase by invoking the `/explore-codebase` skill.

This ensures you:
- Understand the project architecture before modifying code
- Follow existing patterns and conventions
- Don't introduce inconsistencies or break integrations

## Style Guide Requirements

You MUST invoke `/sun-lab-style` and read the appropriate guide before performing ANY of the following tasks:

| Task                              | Guide to Read      |
|-----------------------------------|--------------------|
| Writing or modifying Python code  | PYTHON_STYLE.md    |
| Writing or modifying README files | README_STYLE.md    |
| Writing git commit messages       | COMMIT_STYLE.md    |
| Writing or modifying skill files  | SKILL_STYLE.md     |

This is non-negotiable. The skill contains verification checklists that you MUST complete before submitting any work.
Failure to read the appropriate guide results in style violations.

## Cross-Referenced Library Verification

Sun Lab projects often depend on other `ataraxis-*` or `sl-*` libraries. These libraries may be stored locally in the
same parent directory as this project (`/home/cyberaxolotl/Desktop/GitHubRepos/`).

**Before writing code that interacts with a cross-referenced library, you MUST:**

1. **Check for local version**: Look for the library in the parent directory (e.g., `../ataraxis-video-system/`,
   `../sl-shared-assets/`).

2. **Compare versions**: If a local copy exists, compare its version against the latest release or main branch on
   GitHub:
   - Read the local `pyproject.toml` to get the current version
   - Use `gh api repos/Sun-Lab-NBB/{repo-name}/releases/latest` to check the latest release
   - Alternatively, check the main branch version on GitHub

3. **Handle version mismatches**: If the local version differs from the latest release or main branch, notify the user
   with the following options:
   - **Use online version**: Fetch documentation and API details from the GitHub repository
   - **Update local copy**: The user will pull the latest changes locally before proceeding

4. **Proceed with correct source**: Use whichever version the user selects as the authoritative reference for API
   usage, patterns, and documentation.

**Why this matters**: Skills and documentation may reference outdated APIs. Always verify against the actual library
state to prevent integration errors.

## Available Skills

| Skill                  | Description                                                      |
|------------------------|------------------------------------------------------------------|
| `/explore-codebase`    | Perform in-depth codebase exploration at session start           |
| `/sun-lab-style`       | Apply Sun Lab coding conventions (REQUIRED for all code changes) |
| `/behavior-processing` | Guide behavior data processing workflows using the MCP server    |

## MCP Server

The library includes an MCP server (`sl-behavior mcp`) that exposes behavior data processing tools for AI agents.

### Starting the Server

```bash
sl-behavior mcp
```

### Available Tools

| Tool                          | Purpose                                                           |
|-------------------------------|-------------------------------------------------------------------|
| `start_processing_tool`       | Starts batch processing for one or more sessions with auto-queue  |
| `get_processing_status_tool`  | Returns status for all sessions being managed (no parameters)     |

### Batch Processing Architecture

The MCP server manages batch processing with automatic queuing. The `start_processing_tool` accepts a list of session
paths, calculates optimal parallelization based on CPU cores, and queues sessions beyond the parallel capacity. A
manager thread automatically starts queued sessions as earlier ones complete. The `get_processing_status_tool` returns
status for all managed sessions (active, queued, and completed) without requiring session paths as input.

### Claude Desktop Configuration

Add to your MCP configuration file:

```json
{
  "mcpServers": {
    "sl-behavior": {
      "command": "sl-behavior",
      "args": ["mcp"]
    }
  }
}
```

## Project Context

This is **sl-behavior**, a Python library for processing non-visual behavior data acquired in the Sun Lab at Cornell
University. The library extracts and processes data from `.npz` log archives generated by the sl-experiment library and
saves extracted data as uncompressed `.feather` files for later integration into unified project datasets using the
sl-forgery library.

### Key Areas

| Directory/File                        | Purpose                                                            |
|---------------------------------------|--------------------------------------------------------------------|
| `src/sl_behavior/pipeline.py`         | Central processing orchestration and job management                |
| `src/sl_behavior/runtime.py`          | VR system state, runtime task state, and trial sequence extraction |
| `src/sl_behavior/microcontrollers.py` | Hardware module data parsing (actor, sensor, encoder)              |
| `src/sl_behavior/camera.py`           | Camera timestamp extraction                                        |
| `src/sl_behavior/cli.py`              | CLI entry point for behavior processing commands                   |
| `src/sl_behavior/utilities.py`        | Helper functions for data interpolation                            |

### Architecture

- Job-based processing pipeline with six job types: RUNTIME, FACE_CAMERA, BODY_CAMERA, ACTOR_MICROCONTROLLER,
  SENSOR_MICROCONTROLLER, ENCODER_MICROCONTROLLER
- Supports both local (sequential) and remote (distributed) processing modes
- Uses ProcessPoolExecutor for parallel hardware module parsing
- Numba JIT compilation for performance-critical sequence decomposition
- Input: `.npz` compressed archives; Output: `.feather` files (Apache Arrow format)

### Code Standards

- MyPy strict mode with full type annotations
- Google-style docstrings
- 120 character line limit
- See `/sun-lab-style` for complete conventions

### Workflow Guidance

**Adding a new processing job type:**

1. Add the job name to `BehaviorJobNames` enum in `pipeline.py`
2. Create the processing function in an appropriate module (or new module)
3. Update `_execute_job()` in `pipeline.py` to route to the new processor
4. Update `_resolve_available_jobs()` if the job depends on specific input files
5. Update CLI options in `cli.py` to expose the new job type

**Modifying data extraction:**

1. Identify the target module (`runtime.py` for VR data, `microcontrollers.py` for hardware, `camera.py` for timestamps)
2. Understand the input `.npz` structure from sl-experiment logs
3. Follow existing patterns for extracting, processing, and saving to `.feather` format
4. Use Polars DataFrames for data manipulation

**Adding new hardware module parsers:**

1. Add parser function in `microcontrollers.py` following existing patterns (e.g., `_parse_brake_data`)
2. Update the appropriate extraction function to call the new parser
3. Add module type ID constants as needed
4. Ensure parallel execution compatibility with ProcessPoolExecutor

### Dependencies

This library integrates with several Sun Lab libraries:

| Library                          | Purpose                                              |
|----------------------------------|------------------------------------------------------|
| sl-shared-assets                 | Shared data structures and configuration dataclasses |
| ataraxis-base-utilities          | Console output, error handling, utility functions    |
| ataraxis-video-system            | Camera timestamp extraction                          |
| ataraxis-communication-interface | Hardware communication log parsing                   |
